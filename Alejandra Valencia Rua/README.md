# üìÑ Propuesta Inicial PeerSync

## 1. Problem√°tica del Proyecto

En la educaci√≥n universitaria, el trabajo colaborativo constituye una estrategia pedag√≥gica clave para el desarrollo de competencias t√©cnicas, sociales y profesionales. Sin embargo, los modelos tradicionales de evaluaci√≥n en el aula suelen basarse principalmente en calificaciones asignadas exclusivamente por el docente, lo que limita la participaci√≥n activa del estudiante y no siempre permite capturar de manera precisa el desempe√±o individual dentro de actividades grupales. Este enfoque centrado √∫nicamente en la evaluaci√≥n docente puede generar percepciones de inequidad cuando la nota final de un proyecto colaborativo no refleja el aporte real de cada integrante del equipo. Adem√°s, la concentraci√≥n de la evaluaci√≥n en momentos espec√≠ficos del curso (como entregas finales o ex√°menes) incrementa la presi√≥n acad√©mica y reduce las oportunidades de retroalimentaci√≥n continua.

De acuerdo con Moreno Pab√≥n (2023), los procesos evaluativos en la educaci√≥n superior deben evolucionar hacia modelos m√°s din√°micos y participativos que fomenten la responsabilidad, la reflexi√≥n cr√≠tica y la transparencia en el aprendizaje. La autora resalta la importancia de integrar pr√°cticas que permitan observar el progreso del estudiante y fortalecer su implicaci√≥n activa en los procesos formativos.

En la misma l√≠nea, Basurto-Mendoza et al. (2021) sostienen que las pr√°cticas de coevaluaci√≥n constituyen enfoques innovadores dentro de la pr√°ctica pedag√≥gica, ya que favorecen la identificaci√≥n de vac√≠os de conocimiento, incrementan la motivaci√≥n y promueven el desarrollo de habilidades cr√≠ticas. Asimismo, estas metodolog√≠as proporcionan a los docentes informaci√≥n m√°s aut√©ntica sobre el progreso real de los estudiantes en contextos colaborativos Esta fragmentaci√≥n tecnol√≥gica limita la posibilidad de implementar procesos de retroalimentaci√≥n continua y an√°lisis comparativo del desempe√±o.

En este contexto, se identifica la necesidad de desarrollar una soluci√≥n tecnol√≥gica que permita formalizar la evaluaci√≥n colaborativa mediante una aplicaci√≥n m√≥vil estructurada. De esta manera, el proyecto responde a la necesidad de transformar los procesos tradicionales de evaluaci√≥n en entornos universitarios, integrando fundamentos pedag√≥gicos contempor√°neos con una soluci√≥n tecnol√≥gica estructurada y sostenible.


<br>


## 2. Referentes y An√°lisis del Contexto Actual

Con el fin de fundamentar la propuesta, se realizaron reuniones con profesores del Departamento de Ingenier√≠a de Sistemas de la Universidad del Norte, quienes implementan actividades colaborativas dentro de sus cursos y utilizan distintos mecanismos para evaluar el desempe√±o individual en trabajos grupales.

A partir de estas entrevistas, se identificaron las siguientes herramientas actualmente utilizadas en procesos de coevaluaci√≥n:

### ![http://feedbackfruits.com/rubrics/evaluate-contributions-to-teamwork](https://img.shields.io/badge/FeedbackFruits--purple)

FeedbackFruits es una plataforma integrada com√∫nmente en sistemas LMS que permite implementar din√°micas de retroalimentaci√≥n entre pares.

### Ventajas identificadas:
- Permite evaluaci√≥n estructurada por criterios.
- Facilita la asignaci√≥n de retroalimentaci√≥n entre estudiantes.
- Ofrece cierto nivel de automatizaci√≥n en la recopilaci√≥n de respuestas.

### Limitaciones observadas:
- Dependencia del LMS institucional (como Brisghtspace).
- Interfaz no siempre optimizada para dispositivos m√≥viles.
- Configuraci√≥n avanzada puede resultar compleja.
- Visualizaci√≥n de m√©tricas no siempre personalizada por curso o actividad.

<br>


### ![](https://img.shields.io/badge/Google%20Forms%20/%20Microsoft%20Forms--purple)

Seg√∫n los docentes consultados, una de las pr√°cticas m√°s frecuentes es la creaci√≥n de formularios personalizados con escalas estimativas (por ejemplo, de 1 a 5) para que los estudiantes eval√∫en a sus compa√±eros.

### Ventajas:
- F√°cil creaci√≥n y distribuci√≥n.
- Accesibilidad multiplataforma.
- Flexibilidad en la definici√≥n de preguntas.

### Limitaciones:
- Consolidaci√≥n manual o semiautom√°tica de resultados.
- Ausencia de trazabilidad hist√≥rica integrada.
- No existe diferenciaci√≥n estructurada por rol.
- No hay c√°lculo autom√°tico de m√©tricas por grupo, curso o estudiante.
- No se integran ventanas de tiempo controladas desde la l√≥gica del sistema.  

<br>

Adem√°s de las herramientas mencionadas por los docentes consultados, se realiz√≥ una revisi√≥n exploratoria de soluciones implementadas en contextos universitarios a nivel internacional. Esta b√∫squeda permiti√≥ identificar plataformas especializadas en la evaluaci√≥n del trabajo en equipo que cuentan con respaldo acad√©mico y uso documentado en instituciones de educaci√≥n superior. A continuaci√≥n, se presentan dos referentes adicionales relevantes para el an√°lisis comparativo de la propuesta.

<br>

### ![https://info.catme.org/features/peer-evaluation/](https://img.shields.io/badge/CATME--purple)

CATME (Comprehensive Assessment for Team-Member Effectiveness) es una herramienta ampliamente utilizada en educaci√≥n superior para evaluar la efectividad de los miembros en equipos de trabajo, desorrallad por por un equipo de investigadores, destacando Matthew W. Ohland, Misty L. Loughry, y Richard A. Layton, con apoyo de la National Science Foundation (NSF) y la Universidad de Purdue[^1].

### Ventajas:
- Sistema validado acad√©micamente.
- Evaluaci√≥n por m√∫ltiples dimensiones de desempe√±o.
- Reportes estructurados para docentes.

### Limitaciones:
- Plataforma externa con suscripciones institucionales.
- Menor flexibilidad para personalizaci√≥n espec√≠fica del curso.
- No siempre integrada a flujos acad√©micos internos.
- Interfaz menos intuitiva para uso m√≥vil continuo.

<br>

### ![https://www.youtube.com/watch?v=witnwTevtAk](https://img.shields.io/badge/Moodle%20Workshop%20Module--purple)

El m√≥dulo Workshop de Moodle permite implementar procesos de evaluaci√≥n entre pares dentro del entorno LMS.

### Ventajas:
- Integraci√≥n directa con cursos existentes.
- Gesti√≥n autom√°tica de asignaciones de evaluaci√≥n.
- Configuraci√≥n de r√∫bricas estructuradas.

### Limitaciones:
- Curva de configuraci√≥n compleja.
- Experiencia de usuario poco optimizada para m√≥viles.
- Interfaz centrada en entorno web.
- Visualizaci√≥n anal√≠tica limitada en comparaci√≥n con herramientas especializadas.

<br>

### Hallazgos Generales:

A partir del an√°lisis de estas herramientas y de las entrevistas con docentes, se identifican patrones comunes:

- La mayor√≠a de soluciones no est√°n dise√±adas espec√≠ficamente como aplicaciones m√≥viles nativas.
- La visualizaci√≥n de m√©tricas suele ser limitada o requiere exportaci√≥n manual de datos.
- No existe una integraci√≥n clara entre creaci√≥n de curso, gesti√≥n de grupos, generaci√≥n de actividades y an√°lisis estad√≠stico en una sola herramienta ligera.
- Las soluciones actuales priorizan la recopilaci√≥n de datos, pero no siempre la visualizaci√≥n anal√≠tica estructurada y diferenciada por rol.

<br>

## 3. Composici√≥n y dise√±o de la soluci√≥n
Se propone el desarrollo de una aplicaci√≥n m√≥vil nativa multiplataforma construida en Flutter, que integre en una sola soluci√≥n los roles de docente y estudiante mediante un sistema de autenticaci√≥n con diferenciaci√≥n de vistas seg√∫n perfil.

A diferencia de modelos que separan aplicaciones por rol o dependen exclusivamente de entornos LMS, esta propuesta centraliza la gesti√≥n acad√©mica en una √∫nica aplicaci√≥n, garantizando coherencia de experiencia de usuario, mantenimiento simplificado y futura escalabilidad.

Esta decisi√≥n se justifica por:
- Reducci√≥n de complejidad t√©cnica.
- Unificaci√≥n de autenticaci√≥n.
- Experiencia coherente.
- Facilita futuras extensiones (por ejemplo, rol administrador).

### 3.1. Arquitectura de la Aplicaci√≥n
La soluci√≥n se estructura bajo principios de **Clean Architecture**, organizando el sistema en capas independientes:

**1. Presentation Layer**
- Interfaces gr√°ficas desarrolladas en Flutter.
- Controladores implementados con GetX.
- Manejo de estado reactivo.
- Navegaci√≥n estructurada por roles.

**2. Domain Layer**
- Entidades del sistema (User, Course, GroupCategory, Assessment, Evaluation).
- Casos de uso (CreateCourse, JoinCourse, CreateAssessment, SubmitEvaluation, CalculateMetrics).
- Reglas de negocio:
  - No permitir autoevaluaci√≥n.
  - Respetar ventana de tiempo.
  - Controlar visibilidad p√∫blica o privada.

**3. Data Layer**
- Repositorios.
- Fuentes de datos.
- Persistencia mediante servicios de Roble.

**4. External Services**
- Autenticaci√≥n (correo y contrase√±a).
- Base de datos en Roble.
- Gesti√≥n de almacenamiento estructurado.

<br>

## 4. Flujo Funcional
La aplicaci√≥n implementa un flujo basado en roles (Teacher / Student). Tras iniciar sesi√≥n con correo institucional y contrase√±a, el sistema valida credenciales y consulta en Roble el perfil asociado (rol). Seg√∫n el rol, dirige al usuario a su interfaz correspondiente.

### 4.1. Autenticaci√≥n
1. El usuario ingresa a la app y visualiza **Login**.
2. Ingresa **correo institucional** + **contrase√±a**.
3. El sistema autentica con Roble.
4. Se consulta el perfil del usuario:
   - Si es **Teacher** ‚Üí se carga **Teacher Home**.
   - Si es **Student** ‚Üí se carga **Student Home**.
5. La sesi√≥n se mantiene activa hasta que el usuario haga **Log out**.

### 4.2. Flujo: Rol Teacher

**4.2.1 Navegaci√≥n principal (Teacher)**

NavBar inferior:
- Home
- Cursos
- Perfil

*Acci√≥n global:* **Bot√≥n (+)** (crear curso o crear assessment seg√∫n la pantalla).


**4.2.2 Teacher Home (inicio)**
Al entrar:
- Se muestran todos los **cursos recientes** creados por el docente.
- Se muestran **indicadores globales** del docente.

**Gr√°ficas recomendadas (√∫tiles y alineadas al objetivo):**
1. **Radar por criterios (promedio global)**: Punctuality, Contributions, Commitment, Attitude.
2. **Barras: promedio por curso** (para comparar desempe√±o promedio entre cursos).
3. **L√≠nea temporal: promedio por actividad** (muestra evoluci√≥n del rendimiento de los grupos).

Acci√≥n:
- Bot√≥n flotante **(+) Crear curso**.


**4.2.3 Crear curso**
Al presionar (+):
- Se abre un **popup** con:
  - **Nombre del curso** (obligatorio)
  - **Importar CSV** de categor√≠as/grupos (opcional) *(representa importaci√≥n desde Brightspace)*
  - Botones: ‚úÖ **Crear** | ‚úñÔ∏è **Cancelar**

Al confirmar **Crear**:
1. Se guarda el curso en Roble.
2. El sistema genera un **Course Code** √∫nico (verificaci√≥n privada).
3. Si se import√≥ CSV, se registran:
   - Group Categories
   - Groups
   - Members por group (si vienen en el archivo)

Luego:
- Se navega a la **vista del curso**.



**4.2.4 Vista de Curso**
Encabezado:
- Flecha atr√°s ‚Üê
- **Nombre del curso**
- Acceso r√°pido a **Course Code** (copiar/compartir)

Contenido:
- Lista de **Group Categories** importadas (o estado ‚Äúsin categor√≠as importadas‚Äù).
- Lista de **Assessments** creados (si ya existen).

Acci√≥n:
- Bot√≥n flotante **(+) Crear Assessment**.



**4.2.5 Crear Assessment / Activit**
Al presionar (+):
- Se abre popup con:
  - **Name**
  - **Time window** (duraci√≥n en minutos u horas)
  - **Visibility**
    - **Public**: resultados visibles a miembros del grupo (criterios + score general)
    - **Private**: resultados visibles solo para el docente
  - ‚úÖ **Crear** | ‚úñÔ∏è **Cancelar**

Reglas:
- Assessment queda asociado a una **Group Category** (para saber qu√© equipos participan).
- Se define ventana de tiempo ‚Üí habilita estado **Activa/Expirada**.
- Se habilita evaluaci√≥n entre pares **sin self-evaluation**.

Al crear:
- Se agrega el assessment al listado del curso.



**4.2.6 Resultados por Assessment**
Al abrir un assessment:
1. Se muestra una **gr√°fica general** del desempe√±o en esa actividad:
   - Promedio global de la actividad
   - Radar por criterios (promedio de la actividad)
2. Debajo se listan los **grupos** de la categor√≠a asociada.

Al entrar a un grupo:
- Se muestra tabla/lista con cada integrante:
  - Promedio por criterio
  - **Score general ponderado**
- Opcional: distribuci√≥n (min/max/promedio) para detectar outliers.



**4.2.7 Cursos**
Pantalla ‚ÄúCursos‚Äù muestra:
- Todos los cursos creados
- Acci√≥n (+) **Crear curso** (mismo popup del Home)
- Al abrir un curso ‚Üí mismo flujo descrito en **Vista de Curso**.



**4.2.8 Perfil**
- Datos b√°sicos del docente
- Opci√≥n flotante/men√∫: **Log out**

<br>

### 4.3. Flujo: Rol Student


## 5. Dise√±o del prototipo:
![https://www.figma.com/design/KBR9dHD2k6HqAzglNDpAg4/Movil---Trabajo?node-id=55-4913&t=OhMbymOinxLvQSXz-1](https://img.shields.io/badge/Dise√±o_de_Figma--purple)

## 6. Referencias

* Basurto-Mendoza, S. T., Moreira-Cede√±o, J. A., Vel√°squez-Espinales, A. N., & Rodr√≠guez, M. (2021). Autoevaluaci√≥n, coevaluaci√≥n y heteroevaluaci√≥n como enfoque innovador en la pr√°ctica pedag√≥gica y su efecto en el proceso de ense√±anza-aprendizaje.

* Moreno Pab√≥n, C. (2023). Importancia de la evaluaci√≥n, coevaluaci√≥n y autoevaluaci√≥n en la educaci√≥n universitaria: Experiencias en la Educaci√≥n Art√≠stica. HUMAN Review, 2023(2), 1‚Äì12. 

* Ohland, M. W., Loughry, M. L., Woehr, D. J., Bullard, L. G., Felder, R. M., Finelli, C. J., Layton, R. A., Pomeranz, H. R., & Schmucker, D. G. (2012). The comprehensive assessment of team member effectiveness: Development of a behaviorally anchored rating scale for self- and peer evaluation. Academy of Management Learning & Education, 11(4), 609‚Äì630. https://doi.org/10.5465/amle.2010.0177